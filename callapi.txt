import { useEffect } from 'react';
import useApi from '@/hooks/useApi';
import apiRoutes from '@/services/apiRoutes';

const UserList = () => {
  const { callApi, loading, error } = useApi();

  useEffect(() => {
    const fetchUsers = async () => {
      try {
        await callApi(apiRoutes.users, 'GET', null, null, 'Users loaded!');
      } catch (err) {
        // Error toast already handled in hook
      }
    };

    fetchUsers();
  }, []);

  return (
    <div>
      {loading && <p>Loading users...</p>}
      {error && <p style={{ color: 'red' }}>Error occurred</p>}
    </div>
  );
};

export default UserList;


UPDATE equipment_template SET type = 'indoor' WHERE public_name LIKE '%Indoor%'
UPDATE equipment_template SET type = 'outdoor' WHERE public_name LIKE '%Outdoor%'
UPDATE equipment_template SET type = 'water' WHERE public_name LIKE '%SKU200%'

UPDATE data_feed_device_type_template
SET device_id_mapping = 'EUI',
    timestamp_mapping = '.timestamp',
    timestamp_format = 'UNIX_SECONDS'
WHERE device_type = 'AirScan_Outdoor';

const buildingsTableDataFromRedux = useSelector(
  (state) => state.appData.buildingsTableData,
);
const buildingsTableData =
  localTableData !== undefined ? localTableData : buildingsTableDataFromRedux;
useEffect(() => {
  if (
    localTableData !== undefined &&
    buildingsTableDataFromRedux !== undefined &&
    buildingsTableDataFromRedux !== null
  ) {
    setLocalTableData(undefined);
  }
}, [buildingsTableDataFromRedux]);

Act like a senior solution architect who has experience on building web platform for business which has capability to process huge files uploaded by users using react etc, SA based Bank asked to propose architecture for web platform using frontend backend Tech stack and to be deploy on on-prem internal.

The application should perform below task:
biannual reporting requirement to the South African Revenue Service (SARS)
Report files include IT3B, IT3C, IT3S, and IT3T. These reports cover various entities such as trusts and companies.
ile Processing Flow:
SARS sends data in a specific delimited format (e.g., pipe-delimited CSV).
Files are transferred via Connect Direct to a shared location.
ETL processes are triggered upon file arrival.
Data Storage Optimization:
Current issue: storing large volumes of failed records (e.g., 1 million records per failed file).
Proposal:
Avoid storing full failed files.
Retain only failure logs and rule-level failure details in an audit log table.
Store full data only when the file passes validation.
Audit Logging:
Audit log tables will maintain history of failed records.
File names with timestamps will help in tracking and debugging.


Suggest the architecture component require to cater this functionality.
1) Frontend
2) Backend
3) Data store, audit records of failed files
4) Storage of the passed files
5) Rule Engine that runs on files

ALTER TABLE equipment
ADD COLUMN recalibration_date datetime DEFAULT NULL AFTER longitude,
ADD COLUMN recalibration_status text DEFAULT NULL,
ADD COLUMN recalibration_notes text DEFAULT NULL

